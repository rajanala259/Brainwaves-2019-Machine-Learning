{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](bw.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "** A financial institution news agency has collected 3000 news articles that relates to several matters of financial importance. Before analyzing these unlabeled news, it is only fair to try to partition them into some sort of logical groupings based on their similarities.**\n",
    "\n",
    "**Your task is to use appropriate unsupervised machine learning algorithm to form the news clusters based on their similarity. Prior to clustering it is recommended to perform basic natural language processing steps such as stemming, tokenization and word vectorization for best results.  **\n",
    "\n",
    "Notes to keep in mind:\n",
    "\n",
    "There are no duplicate rows in the dataset.\n",
    "\n",
    "Cluster number should start from 0.\n",
    "\n",
    "### Data Description\n",
    "There is only one file news.csv that contains date, headlines and text of the news.\n",
    "\n",
    "|Column|Description|\n",
    "|------|------|\n",
    "|id|The unique id of the news|\n",
    "|headline|The headline of the news in text|\n",
    "|text|The body of the news in text|\n",
    "\n",
    "\n",
    "### Submission\n",
    "The submission file should be a zip containing a .txt and .csv file. Both should have 3000 rows.\n",
    "\n",
    ".txt file should contain the matrix / ndarrays you are using to create clusters.\n",
    ".csv should contain the cluster of customers against every store.\n",
    "Format of the csv file:\n",
    "\n",
    "|id|cluster|\n",
    "|------|------|\n",
    "|uid-1|0|\n",
    "|uid-2|0|\n",
    "|uid-3|1|\n",
    "|uid-4|1|\n",
    "|uid-5|4|\n",
    "\n",
    "### Evaluation Metric\n",
    "The submissions will be evaluated on silhouette score. Please read more about the metrics here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input/c3cc8568-0-dataset\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1=pd.read_csv('../input/c3cc8568-0-dataset/train.csv')\n",
    "test1=pd.read_csv('../input/c3cc8568-0-dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "596d9325eb745cc9ab4bbbc739ed0ec798d42a1e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "73a54feba5af043f9a0ecb92ed26602e3a9e258a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wt=dict(1-train1['Complaint-Status'].value_counts()/train1.shape[0])\n",
    "wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "335eb38a6c085cdf476816b6e4991e2ec85ee03e",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2d65a1ca3105a24244b45f20512cd1330a56c218",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "739b93a6ae270c9e8dac5064befef6b0ad71b17e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "def clean_text(raw_text):\n",
    "    raw_text=raw_text.strip()\n",
    "    try:\n",
    "        no_encoding=raw_text.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        no_encoding = raw_text\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \",no_encoding) \n",
    "    words = letters_only.lower().split()                             \n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "    meaningful_words1=[stemmer.stem(word) for word in meaningful_words]\n",
    "    return( \" \".join( meaningful_words1 )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8c3d83569624dfbf15395385d330996daae2a049",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import py-translate\n",
    "# translator = Translator()\n",
    "# from nltk.misc import babelfish\n",
    "# smpl=train1['Consumer-complaint-summary'].sample(1,random_state=1994).values\n",
    "# print(smpl)\n",
    "\n",
    "# [w for w in smpl if not w in set(stopwords.words(\"french\")) ]\n",
    "# babelfish.translate(smpl)\n",
    "# print(translator.translate(smpl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1bec2922deb518a11cb926dc2b083e8ea713ab7d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dateSim(val):\n",
    "    if val==0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "train=train1.copy()\n",
    "train['Date-received']=pd.to_datetime(train['Date-received'])\n",
    "train['Date-sent-to-company']=pd.to_datetime(train['Date-sent-to-company'])\n",
    "train['diff'] = train['Date-sent-to-company'] - train['Date-received']\n",
    "train['diff_days']=train['diff']/np.timedelta64(1,'D')\n",
    "train['diff_year']=train['diff']/np.timedelta64(1,'Y')\n",
    "train['diff_m']=train['diff']/np.timedelta64(1,'M')\n",
    "# train['diff_w']=train['diff']/np.timedelta64(1,'W')\n",
    "train['Company-response'].fillna('None',inplace=True)\n",
    "train['Consumer-disputes'].fillna('Other',inplace=True)\n",
    "train['Consumer-complaint-summary']=train['Consumer-complaint-summary'].apply(clean_text)\n",
    "train['Complaint-reason']=train['Complaint-reason'].apply(clean_text)\n",
    "train['isSameDay']=train['diff_days'].apply(dateSim)\n",
    "\n",
    "\n",
    "train['Complaint-reasonLen']=train['Complaint-reason'].apply(len)\n",
    "train['Consumer-complaint-summaryLen']=train['Consumer-complaint-summary'].apply(len)\n",
    "\n",
    "train.drop(['Date-sent-to-company','Date-received','diff'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aef72de507879b894ef5cf0a323e2522566d5c53",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b03d20083b81f44ad99159b6f62db1833626f533",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "df2c6ad1b91329ca6d3660dcf7ac1c2b5b4f7421",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=pd.get_dummies(train,columns=['Transaction-Type','Company-response','Consumer-disputes'],drop_first=True)\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "vec_cr = TfidfVectorizer(ngram_range=(1,2),stop_words=\"english\", analyzer='word')\n",
    "comp_reason =vec_cr.fit_transform(train['Complaint-reason'])\n",
    "\n",
    "vec_cr_char = TfidfVectorizer(ngram_range=(1,8),stop_words=\"english\", analyzer='char')\n",
    "comp_reasonChar =vec_cr_char.fit_transform(train['Complaint-reason'])\n",
    "\n",
    "vec_cs = TfidfVectorizer(ngram_range=(1,3),stop_words=\"english\", analyzer='word')\n",
    "consum_comp_sum =vec_cs.fit_transform(train['Consumer-complaint-summary'])\n",
    "\n",
    "vec_csChar = TfidfVectorizer(ngram_range=(1,9),stop_words=\"english\", analyzer='char')\n",
    "consum_comp_sumChar =vec_csChar.fit_transform(train['Consumer-complaint-summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a682c2fbb7c735e47a42cb8304dab52e27bbbb61",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats=[ 'diff_days', 'diff_year', 'diff_m','Complaint-reasonLen','Consumer-complaint-summaryLen',\n",
    "       'Transaction-Type_Checking or savings account',\n",
    "       'Transaction-Type_Consumer Loan', 'Transaction-Type_Credit card',\n",
    "       'Transaction-Type_Credit card or prepaid card',\n",
    "       'Transaction-Type_Credit reporting',\n",
    "       'Transaction-Type_Credit reporting, credit repair services, or other personal consumer reports',\n",
    "       'Transaction-Type_Debt collection',\n",
    "       'Transaction-Type_Money transfer, virtual currency, or money service',\n",
    "       'Transaction-Type_Money transfers', 'Transaction-Type_Mortgage',\n",
    "       'Transaction-Type_Other financial service',\n",
    "       'Transaction-Type_Payday loan',\n",
    "       'Transaction-Type_Payday loan, title loan, or personal loan',\n",
    "       'Transaction-Type_Prepaid card', 'Transaction-Type_Student loan',\n",
    "       'Transaction-Type_Vehicle loan or lease',\n",
    "       'Transaction-Type_Virtual currency',\n",
    "       'Company-response_Company believes complaint is the result of an isolated error',\n",
    "       'Company-response_Company believes complaint relates to a discontinued policy or procedure',\n",
    "       'Company-response_Company believes complaint represents an opportunity for improvement to better serve consumers',\n",
    "       'Company-response_Company believes it acted appropriately as authorized by contract or law',\n",
    "       'Company-response_Company believes the complaint is the result of a misunderstanding',\n",
    "       \"Company-response_Company can't verify or dispute the facts in the complaint\",\n",
    "       'Company-response_Company chooses not to provide a public response',\n",
    "       'Company-response_Company disputes the facts presented in the complaint',\n",
    "       'Company-response_Company has responded to the consumer and the CFPB and chooses not to provide a public response',\n",
    "       'Company-response_None', 'Consumer-disputes_Other',\n",
    "       'Consumer-disputes_Yes','isSameDay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "de2c76ca361e7fa42350fa8e188bde960b78ea05",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy import sparse\n",
    "final_features = sparse.hstack((train[feats], comp_reason, consum_comp_sum,comp_reasonChar,consum_comp_sumChar)).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1944e3bf383765553a43d8915b29e1464ab28eec",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a74590ec9ff26153041ec56405cbffab29277014",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "X=final_features\n",
    "y=train['Complaint-Status']\n",
    "X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.3,random_state = 1994)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d0ca1a75e518085665842432d5c327f177f068db",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wt={'Closed with explanation': 0.9,\n",
    "#  'Closed with non-monetary relief': 0.5,\n",
    "#  'Closed with monetary relief': 0.8,\n",
    "#  'Closed': 0.8,\n",
    "#  'Untimely response': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c02821e5471018e23112d8f68484fbfc73643b13",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# clf = xgb.XGBClassifier(\n",
    "# #                 max_depth = 5,\n",
    "#                 n_estimators=1000,\n",
    "# #                 learning_rate=0.1, \n",
    "# #                 nthread=4,\n",
    "# #                 subsample=1.0,\n",
    "# #                 colsample_bytree=0.5,\n",
    "# #                 min_child_weight = 3,\n",
    "# #                 scale_pos_weight = ratio,\n",
    "# #                 reg_alpha=0.03,\n",
    "#                 seed=1994,verbose_eval=100)\n",
    "                \n",
    "# clf.fit(X_train, y_train, early_stopping_rounds=50, eval_metric=\"mlogloss\",\n",
    "#         eval_set=[(X_train, y_train), (X_val, y_val)])\n",
    "        \n",
    "# p=clf.predict(X_val, ntree_limit=clf.best_iteration)\n",
    "# print(f1_score(y_val,p,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ee566450be39b177e0dfd316e47bd70a62498424",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# lr=LogisticRegression(verbose=10,class_weight='balanced',C=5,random_state=1994,n_jobs=-1,intercept_scaling=2)\n",
    "# lr.fit(X_train,y_train)\n",
    "# lrpred=lr.predict(X_val)\n",
    "# print(f1_score(y_val,lrpred,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "befa1ce8085b677fba15b7d846a6c5d6d3af15d0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# xgb=XGBClassifier()\n",
    "# xgb.fit(X_train.tocsc(),y_train)\n",
    "# cbpred=xgb.predict(X_val.to_csc())\n",
    "# print(f1_score(y_val,cbpred,average='weighted'))\n",
    "\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# clf = MLPClassifier(verbose=10)\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_pred = clf.predict(X_val)\n",
    "# print(f1_score(y_val,y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bc750626ad7f83cb7ab79f75651ff79f91996f28",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test=test1.copy()\n",
    "test['Date-received']=pd.to_datetime(test['Date-received'])\n",
    "test['Date-sent-to-company']=pd.to_datetime(test['Date-sent-to-company'])\n",
    "test['diff'] = test['Date-sent-to-company'] - test['Date-received']\n",
    "test['diff_days']=test['diff']/np.timedelta64(1,'D')\n",
    "test['diff_year']=test['diff']/np.timedelta64(1,'Y')\n",
    "test['diff_m']=test['diff']/np.timedelta64(1,'M')\n",
    "test['diff_w']=test['diff']/np.timedelta64(1,'W')\n",
    "test['Company-response'].fillna('None',inplace=True)\n",
    "test['Consumer-disputes'].fillna('Other',inplace=True)\n",
    "test['Consumer-complaint-summary']=test['Consumer-complaint-summary'].apply(clean_text)\n",
    "test['Complaint-reason']=test['Complaint-reason'].apply(clean_text)\n",
    "test['isSameDay']=test['diff_days'].apply(dateSim)\n",
    "\n",
    "test['Complaint-reasonLen']=test['Complaint-reason'].apply(len)\n",
    "test['Consumer-complaint-summaryLen']=test['Consumer-complaint-summary'].apply(len)\n",
    "\n",
    "test.drop(['Date-sent-to-company','Date-received','diff'],axis=1,inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bbefd0237d58ff7be1a6c857e23516117360e32a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test=pd.get_dummies(test,columns=['Transaction-Type','Company-response','Consumer-disputes'],drop_first=True)\n",
    "comp_reason_test =vec_cr.transform(test['Complaint-reason'])\n",
    "consum_comp_sum_test =vec_cs.transform(test['Consumer-complaint-summary'])\n",
    "\n",
    "\n",
    "comp_reason_testchar =vec_cr_char.transform(test['Complaint-reason'])\n",
    "consum_comp_sum_testchar =vec_csChar.transform(test['Consumer-complaint-summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6d66d4fa7d277a2bedeb7be12915bf922f8c526d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_features_test = sparse.hstack((test[feats], comp_reason_test, consum_comp_sum_test,comp_reason_testchar,consum_comp_sum_testchar)).tocsr()\n",
    "final_features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da4f2f2f4b2718731619741984a68bd07b9e455d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr=LogisticRegression(verbose=1,class_weight='balanced',C=5,random_state=1996,n_jobs=-1)\n",
    "lr.fit(final_features,train['Complaint-Status'].values)\n",
    "lrpred=lr.predict(final_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "666e7bfe6ec75579fba5a6b4c1a73920a4d043fe",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preds=[]\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# kf = StratifiedKFold(n_splits=3,random_state=1994,shuffle=True)\n",
    "# for train_index,test_index in kf.split(X,y):\n",
    "# #     print('\\n{} of kfold {}'.format(i,kf.n_splits))\n",
    "#     Xtrain,Xtest = X[train_index],X[test_index]\n",
    "#     ytrain,ytest = y[train_index],y[test_index]\n",
    "# #     print(Xtrain.shape,Xtest.shape)\n",
    "# #     print(ytrain.shape,ytest.shape)\n",
    "#     lr=LogisticRegression(verbose=1,class_weight='balanced',C=5,random_state=1994,n_jobs=-1)\n",
    "#     lr.fit(Xtrain,ytrain)\n",
    "#     lrpred=lr.predict(final_features_test)\n",
    "#     preds.append(lrpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a844955611c17052779c1466425ef477109106dd",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in range(len(preds)):\n",
    "#     s=pd.DataFrame({'Complaint-ID':test['Complaint-ID'],'Complaint-Status':preds[i]})\n",
    "#     s.to_csv('lrsKfolds'+str(i)+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "81cb7fbf87cfaece96928efb3a6d6dbdd737ce4f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s=pd.DataFrame({'Complaint-ID':test['Complaint-ID'],'Complaint-Status':lrpred})\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ed8054e73fd1bbb5a028e437a36bfe43ddc414bb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.to_csv('lrs9.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3a52ef0000d6fad88aa59bdc2bffba985595e5c0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# s['Complaint-Status']=mbpred\n",
    "# s.to_csv('mbs1.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
